{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsing import Parser\n",
    "import re\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1052it [07:15,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing replays_raw\\[sc2rep.ru_1565107965]_1x1_TSGSolar(Z)_llllllllllll(P).SC2Replay: Replacement index 2 out of range for positional args tuple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1720it [13:33,  2.11it/s]\n"
     ]
    }
   ],
   "source": [
    "parser = Parser('replays_raw')\n",
    "replays_data = parser.parse_replays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1719 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1719/1719 [00:08<00:00, 198.18it/s]\n"
     ]
    }
   ],
   "source": [
    "save_path = 'replays_processed/baseline/processed_replays.pt'\n",
    "\n",
    "def concatenate_rows_single_last_column(tensor):\n",
    "    sorted_tensor, indices = torch.sort(tensor, dim=0, descending=False)\n",
    "    last_col_vals = sorted_tensor[:, -1]\n",
    "    unique_vals, counts = torch.unique(last_col_vals, return_counts=True)\n",
    "    paired_indices = unique_vals[counts == 2]\n",
    "    mask = torch.isin(last_col_vals, paired_indices)\n",
    "    to_concatenate = sorted_tensor[mask]\n",
    "    to_concatenate = to_concatenate.view(-1, 2, to_concatenate.size(1))\n",
    "    concatenated = torch.cat((to_concatenate[:, 0, :-1], to_concatenate[:, 1, :]), dim=1)\n",
    "    return concatenated\n",
    "\n",
    "full_data = []\n",
    "for game in tqdm(replays_data):\n",
    "    game_data = []\n",
    "    replay = game[0]\n",
    "    winner_text = game[1]\n",
    "    winner = 2-int(re.search(r\"Team (\\d+)\", str(winner_text)).group(1))\n",
    "    for timestep in replay:\n",
    "        stats = torch.tensor(list(timestep.stats.values()))\n",
    "        second = torch.tensor(timestep.second).unsqueeze(0)\n",
    "        full_stats = torch.concat((stats, second), dim=-1)\n",
    "        game_data.append(full_stats)\n",
    "    game_data_tensor = torch.stack(game_data)\n",
    "    game_data_tensor = concatenate_rows_single_last_column(game_data_tensor)\n",
    "    win_tensor = torch.full((game_data_tensor.size(0), 1), winner)\n",
    "    game_tensor = torch.cat((game_data_tensor, win_tensor), dim=1)\n",
    "    full_data.append(game_tensor)\n",
    "full_data_tensor = torch.concat(full_data, dim=0)\n",
    "torch.save(full_data_tensor, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Dataloader (execute from here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([169701, 80])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "save_path = 'replays_processed/baseline/processed_replays.pt'\n",
    "full_data_tensor = torch.load(save_path)\n",
    "full_data_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the TensorDataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "hidden_size = 64\n",
    "learning_rate = 1e-3\n",
    "epochs = 500\n",
    "\n",
    "features = full_data_tensor[:, :-1]\n",
    "labels = full_data_tensor[:, -1].long()\n",
    "dataset = TensorDataset(features, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 79])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the baseline MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ffwd = nn.Sequential(\n",
    "            nn.BatchNorm1d(79),\n",
    "            nn.Linear(79, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.ffwd(x)\n",
    "\n",
    "model = MLPClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=learning_rate)  # Using Adam optimizer\n",
    "bceloss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Batch 0, Loss: 0.7104644775390625\n",
      "Epoch [6/500], Batch 0, Loss: 0.5893709063529968\n",
      "Epoch [11/500], Batch 0, Loss: 0.5423356294631958\n",
      "Epoch [16/500], Batch 0, Loss: 0.5362827777862549\n",
      "Epoch [21/500], Batch 0, Loss: 0.5354219079017639\n",
      "Epoch [26/500], Batch 0, Loss: 0.4985294044017792\n",
      "Epoch [31/500], Batch 0, Loss: 0.5103408694267273\n",
      "Epoch [36/500], Batch 0, Loss: 0.4838268756866455\n",
      "Epoch [41/500], Batch 0, Loss: 0.48968470096588135\n",
      "Epoch [46/500], Batch 0, Loss: 0.4690924286842346\n",
      "Epoch [51/500], Batch 0, Loss: 0.4963911175727844\n",
      "Epoch [56/500], Batch 0, Loss: 0.49744921922683716\n",
      "Epoch [61/500], Batch 0, Loss: 0.4513827860355377\n",
      "Epoch [66/500], Batch 0, Loss: 0.4415157437324524\n",
      "Epoch [71/500], Batch 0, Loss: 0.4613882601261139\n",
      "Epoch [76/500], Batch 0, Loss: 0.4552359879016876\n",
      "Epoch [81/500], Batch 0, Loss: 0.49122709035873413\n",
      "Epoch [86/500], Batch 0, Loss: 0.4760972857475281\n",
      "Epoch [91/500], Batch 0, Loss: 0.4421740174293518\n",
      "Epoch [96/500], Batch 0, Loss: 0.4339776337146759\n",
      "Epoch [101/500], Batch 0, Loss: 0.45964038372039795\n",
      "Epoch [106/500], Batch 0, Loss: 0.4487297534942627\n",
      "Epoch [111/500], Batch 0, Loss: 0.44653332233428955\n",
      "Epoch [116/500], Batch 0, Loss: 0.40824219584465027\n",
      "Epoch [121/500], Batch 0, Loss: 0.44138842821121216\n",
      "Epoch [126/500], Batch 0, Loss: 0.43189406394958496\n",
      "Epoch [131/500], Batch 0, Loss: 0.4547237753868103\n",
      "Epoch [136/500], Batch 0, Loss: 0.46567028760910034\n",
      "Epoch [141/500], Batch 0, Loss: 0.4438515603542328\n",
      "Epoch [146/500], Batch 0, Loss: 0.4501252770423889\n",
      "Epoch [151/500], Batch 0, Loss: 0.4329790771007538\n",
      "Epoch [156/500], Batch 0, Loss: 0.42205461859703064\n",
      "Epoch [161/500], Batch 0, Loss: 0.43871864676475525\n",
      "Epoch [166/500], Batch 0, Loss: 0.4499151110649109\n",
      "Epoch [171/500], Batch 0, Loss: 0.4187200665473938\n",
      "Epoch [176/500], Batch 0, Loss: 0.4562566578388214\n",
      "Epoch [181/500], Batch 0, Loss: 0.3962188959121704\n",
      "Epoch [186/500], Batch 0, Loss: 0.4234778583049774\n",
      "Epoch [191/500], Batch 0, Loss: 0.4299237132072449\n",
      "Epoch [196/500], Batch 0, Loss: 0.41979360580444336\n",
      "Epoch [201/500], Batch 0, Loss: 0.40510427951812744\n",
      "Epoch [206/500], Batch 0, Loss: 0.4062875509262085\n",
      "Epoch [211/500], Batch 0, Loss: 0.41792091727256775\n",
      "Epoch [216/500], Batch 0, Loss: 0.41603344678878784\n",
      "Epoch [221/500], Batch 0, Loss: 0.43147996068000793\n",
      "Epoch [226/500], Batch 0, Loss: 0.4431169331073761\n",
      "Epoch [231/500], Batch 0, Loss: 0.3875446319580078\n",
      "Epoch [236/500], Batch 0, Loss: 0.39122283458709717\n",
      "Epoch [241/500], Batch 0, Loss: 0.4305570125579834\n",
      "Epoch [246/500], Batch 0, Loss: 0.4176352322101593\n",
      "Epoch [251/500], Batch 0, Loss: 0.4465096890926361\n",
      "Epoch [256/500], Batch 0, Loss: 0.44200125336647034\n",
      "Epoch [261/500], Batch 0, Loss: 0.3990577459335327\n",
      "Epoch [266/500], Batch 0, Loss: 0.4187476634979248\n",
      "Epoch [271/500], Batch 0, Loss: 0.417982816696167\n",
      "Epoch [276/500], Batch 0, Loss: 0.4490836262702942\n",
      "Epoch [281/500], Batch 0, Loss: 0.404895544052124\n",
      "Epoch [286/500], Batch 0, Loss: 0.40687426924705505\n",
      "Epoch [291/500], Batch 0, Loss: 0.4187880754470825\n",
      "Epoch [296/500], Batch 0, Loss: 0.41205549240112305\n",
      "Epoch [301/500], Batch 0, Loss: 0.43387919664382935\n",
      "Epoch [306/500], Batch 0, Loss: 0.41504842042922974\n",
      "Epoch [311/500], Batch 0, Loss: 0.42459553480148315\n",
      "Epoch [316/500], Batch 0, Loss: 0.4034285545349121\n",
      "Epoch [321/500], Batch 0, Loss: 0.43519043922424316\n",
      "Epoch [326/500], Batch 0, Loss: 0.39639976620674133\n",
      "Epoch [331/500], Batch 0, Loss: 0.43912458419799805\n",
      "Epoch [336/500], Batch 0, Loss: 0.42472028732299805\n",
      "Epoch [341/500], Batch 0, Loss: 0.40099161863327026\n",
      "Epoch [346/500], Batch 0, Loss: 0.3984614610671997\n",
      "Epoch [351/500], Batch 0, Loss: 0.4089289903640747\n",
      "Epoch [356/500], Batch 0, Loss: 0.43083739280700684\n",
      "Epoch [361/500], Batch 0, Loss: 0.393951952457428\n",
      "Epoch [366/500], Batch 0, Loss: 0.40765705704689026\n",
      "Epoch [371/500], Batch 0, Loss: 0.4002790153026581\n",
      "Epoch [376/500], Batch 0, Loss: 0.4064996838569641\n",
      "Epoch [381/500], Batch 0, Loss: 0.38159844279289246\n",
      "Epoch [386/500], Batch 0, Loss: 0.41158390045166016\n",
      "Epoch [391/500], Batch 0, Loss: 0.44966259598731995\n",
      "Epoch [396/500], Batch 0, Loss: 0.46298709511756897\n",
      "Epoch [401/500], Batch 0, Loss: 0.3758578896522522\n",
      "Epoch [406/500], Batch 0, Loss: 0.4506734013557434\n",
      "Epoch [411/500], Batch 0, Loss: 0.3913053274154663\n",
      "Epoch [416/500], Batch 0, Loss: 0.39274585247039795\n",
      "Epoch [421/500], Batch 0, Loss: 0.4236462116241455\n",
      "Epoch [426/500], Batch 0, Loss: 0.4275062084197998\n",
      "Epoch [431/500], Batch 0, Loss: 0.4241580367088318\n",
      "Epoch [436/500], Batch 0, Loss: 0.3865899443626404\n",
      "Epoch [441/500], Batch 0, Loss: 0.39256876707077026\n",
      "Epoch [446/500], Batch 0, Loss: 0.4126104712486267\n",
      "Epoch [451/500], Batch 0, Loss: 0.4021780788898468\n",
      "Epoch [456/500], Batch 0, Loss: 0.39524197578430176\n",
      "Epoch [461/500], Batch 0, Loss: 0.39761489629745483\n",
      "Epoch [466/500], Batch 0, Loss: 0.3893332779407501\n",
      "Epoch [471/500], Batch 0, Loss: 0.3640593886375427\n",
      "Epoch [476/500], Batch 0, Loss: 0.40717414021492004\n",
      "Epoch [481/500], Batch 0, Loss: 0.3831069767475128\n",
      "Epoch [486/500], Batch 0, Loss: 0.39201658964157104\n",
      "Epoch [491/500], Batch 0, Loss: 0.3842833638191223\n",
      "Epoch [496/500], Batch 0, Loss: 0.3923916220664978\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch_idx, (x, labels) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(x.float())\n",
    "        labels = labels.unsqueeze(1).float()\n",
    "        loss = bceloss(out, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (int(batch_idx) == 0) & (epoch % 5 == 0):\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Batch {batch_idx}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:tensor([925]), predicted win rate: tensor([[0.5591],\n",
      "        [0.5779],\n",
      "        [0.5547],\n",
      "        [0.5588],\n",
      "        [0.5522],\n",
      "        [0.5461],\n",
      "        [0.5373],\n",
      "        [0.5350],\n",
      "        [0.5282],\n",
      "        [0.5276],\n",
      "        [0.5214],\n",
      "        [0.5136],\n",
      "        [0.5146],\n",
      "        [0.5066],\n",
      "        [0.5110],\n",
      "        [0.5125],\n",
      "        [0.5127],\n",
      "        [0.5152],\n",
      "        [0.5077],\n",
      "        [0.5092],\n",
      "        [0.4970],\n",
      "        [0.4873],\n",
      "        [0.5340],\n",
      "        [0.5264],\n",
      "        [0.5074],\n",
      "        [0.5081],\n",
      "        [0.4966],\n",
      "        [0.4536],\n",
      "        [0.4038],\n",
      "        [0.3600],\n",
      "        [0.4010],\n",
      "        [0.4298],\n",
      "        [0.3433],\n",
      "        [0.3794],\n",
      "        [0.4067],\n",
      "        [0.5139],\n",
      "        [0.4984],\n",
      "        [0.5696],\n",
      "        [0.6665],\n",
      "        [0.6261],\n",
      "        [0.5215],\n",
      "        [0.5941],\n",
      "        [0.5126],\n",
      "        [0.6159],\n",
      "        [0.6960],\n",
      "        [0.7614],\n",
      "        [0.7909],\n",
      "        [0.3387],\n",
      "        [0.2834],\n",
      "        [0.6304],\n",
      "        [0.7494],\n",
      "        [0.8203],\n",
      "        [0.7824],\n",
      "        [0.7386],\n",
      "        [0.7828],\n",
      "        [0.7773],\n",
      "        [0.9021],\n",
      "        [0.9142],\n",
      "        [0.8042],\n",
      "        [0.7138],\n",
      "        [0.7295],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [1.0000],\n",
      "        [0.9993],\n",
      "        [0.9980],\n",
      "        [0.9934],\n",
      "        [0.9954],\n",
      "        [0.9996],\n",
      "        [0.9977],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9864],\n",
      "        [0.9464],\n",
      "        [0.9920],\n",
      "        [0.9968],\n",
      "        [0.9998],\n",
      "        [0.9999],\n",
      "        [0.9978],\n",
      "        [0.9916],\n",
      "        [0.9999],\n",
      "        [0.9994],\n",
      "        [0.9934],\n",
      "        [0.9955],\n",
      "        [0.9971],\n",
      "        [0.9952],\n",
      "        [0.9870],\n",
      "        [0.9872],\n",
      "        [0.9324],\n",
      "        [0.9262],\n",
      "        [0.9519]])\n"
     ]
    }
   ],
   "source": [
    "import sc2reader\n",
    "model.eval()\n",
    "\n",
    "@torch.no_grad\n",
    "def test_replay():\n",
    "    game_data = []\n",
    "    replay = sc2reader.load_replay('test.SC2Replay')\n",
    "    for event in replay.events:\n",
    "        if event.name == \"PlayerStatsEvent\":\n",
    "            stats = torch.tensor(list(event.stats.values()))\n",
    "            time = torch.tensor(event.second).unsqueeze(0)\n",
    "            x = torch.concat((stats, time))\n",
    "            game_data.append(x)\n",
    "    game_data_tensor = torch.stack(game_data)\n",
    "    game_data_tensor = concatenate_rows_single_last_column(game_data_tensor)\n",
    "    print(f'time:{time}, predicted win rate: {model(game_data_tensor.float())}')\n",
    "\n",
    "test_replay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
